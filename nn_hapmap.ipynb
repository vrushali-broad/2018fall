{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn_hapmap.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vrushali-broad/2018fall/blob/master/nn_hapmap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_PyDY_9D_a1",
        "colab_type": "code",
        "outputId": "cb7561a2-b0ec-410b-d3ef-70ac15890ce3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "## Check if GPU is available\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gdc1dnHnF70u",
        "colab_type": "code",
        "outputId": "9da5e243-b376-41f1-b51a-85daf21a59e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "## Mount Google drive to import data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSqIm-6qGFMf",
        "colab_type": "code",
        "outputId": "57560695-0a2a-460c-f197-6581cf62e66b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "%cd '/content/drive/My Drive/mutpip_paper/'\n",
        "!ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/mutpip_paper\n",
            " 19_logs\t       input.csv\t\t  result_fm.pkl\n",
            " best_model_gp.keras  'July 2019 Notebook.gdoc'   result_gbrt.pkl\n",
            " hapmap.ids.txt        nn_hapmap.ipynb\t\t  result_gp.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GArUyYcFSfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Import libraries\n",
        "import pandas as pd\n",
        "from numpy import loadtxt\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Epn1S2F32Bv",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E9wheGVJGCLf",
        "colab_type": "code",
        "outputId": "1fd8a85b-cfb5-4ef9-80ab-ea8641ca1538",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "## input.csv is generated from *.ug.raw.vcf file in RVBoost (input for RVBoost.R)\n",
        "## The label is 1 if the SNP is present in HAPMAP otherwise 0\n",
        "df = pd.read_csv('input.csv',sep='\\t', low_memory=False)\n",
        "df.head()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DJ</th>\n",
              "      <th>PctExtPos</th>\n",
              "      <th>ReadPosRankSum</th>\n",
              "      <th>QD</th>\n",
              "      <th>FS</th>\n",
              "      <th>ED</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>chr1:14522_G/A</th>\n",
              "      <td>161</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.400</td>\n",
              "      <td>0.82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chr1:14542_A/G</th>\n",
              "      <td>181</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.204</td>\n",
              "      <td>4.94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chr1:14574_A/G</th>\n",
              "      <td>213</td>\n",
              "      <td>0.25</td>\n",
              "      <td>2.339</td>\n",
              "      <td>4.11</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chr1:14590_G/A</th>\n",
              "      <td>229</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.750</td>\n",
              "      <td>4.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chr1:14599_T/A</th>\n",
              "      <td>230</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.083</td>\n",
              "      <td>8.39</td>\n",
              "      <td>0.0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 DJ  PctExtPos  ReadPosRankSum    QD   FS  ED  label\n",
              "chr1:14522_G/A  161       0.00           0.400  0.82  0.0   8      0\n",
              "chr1:14542_A/G  181       0.00           0.204  4.94  0.0   8      0\n",
              "chr1:14574_A/G  213       0.25           2.339  4.11  0.0   8      0\n",
              "chr1:14590_G/A  229       0.00           0.750  4.46  0.0   8      0\n",
              "chr1:14599_T/A  230       0.00           1.083  8.39  0.0   8      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEOjuOCVFprF",
        "colab_type": "code",
        "outputId": "d6df76d1-9ddf-4d2f-e74b-001f38c5bb04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# load the dataset\n",
        "dataset = pd.read_csv('input.csv',sep='\\t', low_memory=False)\n",
        "from sklearn import preprocessing\n",
        "\n",
        "x = dataset.values #returns a numpy array\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scaled = min_max_scaler.fit_transform(x)\n",
        "df = pd.DataFrame(x_scaled)\n",
        "df.head()\n",
        "\n",
        "\n",
        "# split into input (X) and output (y) variables\n",
        "X = dataset.loc[:,['DJ','PctExtPos','ReadPosRankSum','QD','FS','ED']]\n",
        "y = dataset.loc[:,['label']]\n",
        "#X = df.loc[:,0:5]\n",
        "#y = df.loc[:,6]\n",
        "\n",
        "## Check size of the training data and labels\n",
        "X.shape, y.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((44107, 6), (44107, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDIiBUG41T7X",
        "colab_type": "code",
        "outputId": "adbe8960-66ab-49b2-945e-358f7a7078d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "X.tail(2),y.tail(2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                     DJ  PctExtPos  ReadPosRankSum     QD     FS  ED\n",
              " chr9:140167022_G/A   45       0.04           1.810  12.74  8.470   1\n",
              " chr9:140167877_T/G  123       0.00           0.019  10.12  0.946   1,\n",
              "                     label\n",
              " chr9:140167022_G/A      0\n",
              " chr9:140167877_T/G      1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gNfZYcD15fF4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "2209dd6f-70ff-448b-95b7-143b17843a53"
      },
      "source": [
        "import seaborn as sns\n",
        "corr = X.corr()\n",
        "sns.heatmap(corr, \n",
        "            xticklabels=corr.columns.values,\n",
        "            yticklabels=corr.columns.values)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fc45210db38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAa0AAAFMCAYAAAB4TuMQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nojH+P7suEvW412uYAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OO6OMGi77yg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Whitening the data - normalization\n",
        "cols = list(X.columns)\n",
        "\n",
        "train_mean = X[cols].mean(axis=0)\n",
        "train_std = X[cols].std(axis=0)\n",
        "X[cols] = (X[cols] - train_mean) / train_std\n",
        "#validate[cols] = (validate[cols] - train_mean) / train_std\n",
        "#test[cols] = (test[cols] - train_mean) / train_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7kAUlsv7nIH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e14667a-515f-43d2-ed36-be49504fc864"
      },
      "source": [
        "## Split into train and test data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, shuffle= True)\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((30874, 6), (13233, 6), (30874, 1), (13233, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0miVV7h3xJm",
        "colab_type": "text"
      },
      "source": [
        "### Train Neural Net from DeepPVP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scuCfQXNHkVv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "fe4c00a5-29d1-4523-ff41-fe136fb4c339"
      },
      "source": [
        "## Model from DeepPVP paper\n",
        "from keras.regularizers import l1\n",
        "import keras\n",
        "reg = l1(0.001)\n",
        "opt = keras.optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(67, input_dim=6, activation='relu',activity_regularizer=l1(0.001)))\n",
        "model.add(Dense(32, activation='relu',activity_regularizer=l1(0.001)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 18:19:33.941071 139778003031936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0809 18:19:33.942867 139778003031936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0809 18:19:33.945451 139778003031936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0809 18:19:34.004472 139778003031936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0809 18:19:34.013256 139778003031936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0809 18:19:34.021572 139778003031936 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOecRtHvHtMH",
        "colab_type": "code",
        "outputId": "348140ef-c7f8-4ecf-dda3-0d5f268fcf5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "## Run Model\n",
        "model.fit(X, y, epochs=50, batch_size=1500)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "44107/44107 [==============================] - 3s 79us/step - loss: 11.0955 - acc: 0.7246\n",
            "Epoch 2/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 4.6437 - acc: 0.7246\n",
            "Epoch 3/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 1.8864 - acc: 0.7246\n",
            "Epoch 4/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.8778 - acc: 0.7246\n",
            "Epoch 5/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.6365 - acc: 0.7246\n",
            "Epoch 6/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5950 - acc: 0.7246\n",
            "Epoch 7/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5901 - acc: 0.7246\n",
            "Epoch 8/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5893 - acc: 0.7246\n",
            "Epoch 9/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.5890 - acc: 0.7246\n",
            "Epoch 10/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 11/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 12/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 13/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 14/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 15/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 16/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 17/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 18/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 19/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 20/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 21/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 22/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 23/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 24/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 25/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 26/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 27/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5889 - acc: 0.7246\n",
            "Epoch 28/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 29/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 30/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 31/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 32/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 33/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 34/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 35/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 36/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 37/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 38/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 39/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 40/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 41/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 42/50\n",
            "44107/44107 [==============================] - 0s 3us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 43/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 44/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 45/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5886 - acc: 0.7246\n",
            "Epoch 46/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 47/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n",
            "Epoch 48/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 49/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5888 - acc: 0.7246\n",
            "Epoch 50/50\n",
            "44107/44107 [==============================] - 0s 4us/step - loss: 0.5887 - acc: 0.7246\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f1fbbddac18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDPFkfhf3BFb",
        "colab_type": "text"
      },
      "source": [
        "Since the accuracy stays constant at 72% even after 50 epochs, let's tune the model.\n",
        "***\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJhkoXfz3qxO",
        "colab_type": "text"
      },
      "source": [
        "### Model Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_6jA-7i2_MU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "e36eb8d7-62dc-4e19-fff4-7028e0f460d7"
      },
      "source": [
        "from keras.regularizers import l1\n",
        "import keras\n",
        "reg = l1(0.001)\n",
        "opt = keras.optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=6, activation='relu',activity_regularizer=l1(0.001)))\n",
        "model.add(Dense(128, activation='relu',activity_regularizer=l1(0.001)))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "## Run Model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.33) #validation_data=(X_test, y_test))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20685 samples, validate on 10189 samples\n",
            "Epoch 1/10\n",
            "20685/20685 [==============================] - 4s 194us/step - loss: 0.5607 - acc: 0.7261 - val_loss: 0.5121 - val_acc: 0.7204\n",
            "Epoch 2/10\n",
            "20685/20685 [==============================] - 3s 148us/step - loss: 0.5107 - acc: 0.7267 - val_loss: 0.5072 - val_acc: 0.7204\n",
            "Epoch 3/10\n",
            "20685/20685 [==============================] - 3s 151us/step - loss: 0.5013 - acc: 0.7267 - val_loss: 0.5010 - val_acc: 0.7204\n",
            "Epoch 4/10\n",
            "20685/20685 [==============================] - 3s 160us/step - loss: 0.5010 - acc: 0.7267 - val_loss: 0.4971 - val_acc: 0.7204\n",
            "Epoch 5/10\n",
            "20685/20685 [==============================] - 3s 163us/step - loss: 0.4961 - acc: 0.7267 - val_loss: 0.5222 - val_acc: 0.7204\n",
            "Epoch 6/10\n",
            "20685/20685 [==============================] - 3s 157us/step - loss: 0.4970 - acc: 0.7267 - val_loss: 0.4903 - val_acc: 0.7204\n",
            "Epoch 7/10\n",
            "20685/20685 [==============================] - 3s 158us/step - loss: 0.4944 - acc: 0.7267 - val_loss: 0.4918 - val_acc: 0.7204\n",
            "Epoch 8/10\n",
            "20685/20685 [==============================] - 3s 150us/step - loss: 0.4917 - acc: 0.7267 - val_loss: 0.4892 - val_acc: 0.7204\n",
            "Epoch 9/10\n",
            "20685/20685 [==============================] - 3s 148us/step - loss: 0.4916 - acc: 0.7267 - val_loss: 0.4825 - val_acc: 0.7204\n",
            "Epoch 10/10\n",
            "20685/20685 [==============================] - 3s 158us/step - loss: 0.4908 - acc: 0.7267 - val_loss: 0.5266 - val_acc: 0.7204\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc4408bda20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFsUHQGeoFQ-",
        "colab_type": "code",
        "outputId": "d7e4b10c-53c3-49b2-d40e-cad63a8ecef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "y_pred = model.predict_classes(X_test)\n",
        "\n",
        "1 - np.sum(y_test-y_pred)/len(y_pred)\n",
        "#ynew = model.predict(X_test)\n",
        "#ynew[ynew>0.3]"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.39688984, 0.36464757, 0.3770936 , ..., 0.39688984, 0.39688984,\n",
              "       0.39688984], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEiDR3Rhov40",
        "colab_type": "code",
        "outputId": "4a099b4f-39fc-47e6-a7fa-56ee9818975a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "(y_pred[y_pred>0.6])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.72334087, 0.63284224, 0.60308313, 0.6625936 , 0.60655105,\n",
              "       0.9171456 , 0.61723465, 0.6180813 , 0.6043245 , 0.97198725,\n",
              "       0.7804998 , 0.6041637 , 0.61482203, 0.6706109 , 0.6072044 ,\n",
              "       0.6044082 ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ibp99JnEYAT",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu8D-1AWEhpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "d04c3d77-c6de-4fb0-cc70-c908f16b6bf7"
      },
      "source": [
        "pip install scikit-optimize"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/44/60f82c97d1caa98752c7da2c1681cab5c7a390a0fdd3a55fac672b321cac/scikit_optimize-0.5.2-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 1.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.21.3)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.19.1->scikit-optimize) (0.13.2)\n",
            "Installing collected packages: scikit-optimize\n",
            "Successfully installed scikit-optimize-0.5.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUaUtfhzExlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(learning_rate, num_dense_layers, num_dense_nodes, activation):\n",
        "    \"\"\"\n",
        "    Hyper-parameters:\n",
        "    learning_rate:     Learning-rate for the optimizer.\n",
        "    num_dense_layers:  Number of dense layers.\n",
        "    num_dense_nodes:   Number of nodes in each dense layer.\n",
        "    activation:        Activation function for all layers.\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(Dense(64, input_dim=6, activation='relu',activity_regularizer=l1(0.001)))\n",
        "    for i in range(num_dense_layers):\n",
        "        name = 'layer_dense_{0}'.format(i+1)\n",
        "        model.add(Dense(num_dense_nodes,\n",
        "                        activation=activation,\n",
        "                        name=name))\n",
        "\n",
        "    model.add(Dense(1, activation='softmax'))\n",
        "    optimizer = Adam(lr=learning_rate)\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP_ylslmExsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Function to be optimized in skopt and hyperopt\n",
        "@use_named_args(parameters)\n",
        "def optimization(learning_rate, num_dense_layers,\n",
        "            num_dense_nodes, activation):\n",
        "\n",
        "    # Print the hyperparameters at each point\n",
        "    print('learning rate: {0:.1e}'.format(learning_rate))\n",
        "    print('num_dense_layers:', num_dense_layers)\n",
        "    print('num_dense_nodes:', num_dense_nodes)\n",
        "    print('activation:', activation)\n",
        "    print()\n",
        "    \n",
        "    # Generate a model\n",
        "    model = create_model(learning_rate=learning_rate,\n",
        "                         num_dense_layers=num_dense_layers,\n",
        "                         num_dense_nodes=num_dense_nodes,\n",
        "                         activation=activation)\n",
        "    \n",
        "    model.summary()\n",
        "    # Train the model\n",
        "    history = model.fit(x=X_train,\n",
        "                        y=y_train,\n",
        "                        epochs=3,\n",
        "                        batch_size=128,\n",
        "                        validation_data=(X_test, y_test))\n",
        "\n",
        "    # Classification accuracy on validation set\n",
        "    accuracy = history.history['val_acc'][-1]\n",
        "\n",
        "    # Print the classification accuracy.\n",
        "    print(\"Accuracy: {0:.2%}\".format(accuracy))\n",
        "    return -accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGOe0m31bPLJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## skopt\n",
        "import skopt\n",
        "from skopt import dump, load\n",
        "from skopt import gp_minimize, forest_minimize, gbrt_minimize\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from skopt.plots import plot_convergence\n",
        "from skopt.utils import use_named_args\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "start_parameters = [1e-5, 1, 16, 'relu']  ## Manual tuning\n",
        "learning_rate = Real(low=1e-6, high=1e-2, prior='log-uniform', name='learning_rate')\n",
        "num_dense_layers = Integer(low=1, high=5, name='num_dense_layers')\n",
        "num_dense_nodes = Integer(low=5, high=512, name='num_dense_nodes')\n",
        "activation = Categorical(categories=['relu', 'sigmoid','tanh'],name='activation')\n",
        "\n",
        "parameters = [learning_rate, num_dense_layers, num_dense_nodes, activation]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGo11itPcV3S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install keras==2.1\n",
        "#import keras\n",
        "#print(keras.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCtRy_BYExvN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3c5d55ae-5bcc-407a-f7d4-52ccb770bdc9"
      },
      "source": [
        "## GP\n",
        "search_result = gp_minimize(func=optimization,\n",
        "                            dimensions=parameters,\n",
        "                            acq_func='EI',\n",
        "                            n_calls=40, x0=start_parameters)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "learning rate: 1.0e-05\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 16\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_17 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "dense_18 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 1,505\n",
            "Trainable params: 1,505\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0809 18:23:49.505858 139778003031936 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 131us/step - loss: 12.5842 - acc: 0.2756 - val_loss: 12.5724 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 33us/step - loss: 12.5616 - acc: 0.2756 - val_loss: 12.5500 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 30us/step - loss: 12.5395 - acc: 0.2756 - val_loss: 12.5278 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 6.6e-03\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 346\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_19 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 346)               22490     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 346)               120062    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 346)               120062    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 346)               120062    \n",
            "_________________________________________________________________\n",
            "dense_20 (Dense)             (None, 1)                 347       \n",
            "=================================================================\n",
            "Total params: 383,471\n",
            "Trainable params: 383,471\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 51us/step - loss: 11.5973 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.6e-03\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 397\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_21 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 397)               25805     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 397)               158006    \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 1)                 398       \n",
            "=================================================================\n",
            "Total params: 184,657\n",
            "Trainable params: 184,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 1s 46us/step - loss: 11.7523 - acc: 0.2756 - val_loss: 11.5565 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 32us/step - loss: 11.5495 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 32us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.9e-05\n",
            "num_dense_layers: 2\n",
            "num_dense_nodes: 209\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_23 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 209)               13585     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 209)               43890     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 1)                 210       \n",
            "=================================================================\n",
            "Total params: 58,133\n",
            "Trainable params: 58,133\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 1s 48us/step - loss: 12.5846 - acc: 0.2756 - val_loss: 12.5588 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 32us/step - loss: 12.5422 - acc: 0.2756 - val_loss: 12.5167 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 31us/step - loss: 12.5002 - acc: 0.2756 - val_loss: 12.4751 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 4.8e-05\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 30\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_25 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 30)                1950      \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_26 (Dense)             (None, 1)                 31        \n",
            "=================================================================\n",
            "Total params: 5,219\n",
            "Trainable params: 5,219\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 58us/step - loss: 12.5221 - acc: 0.2756 - val_loss: 12.4656 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.4183 - acc: 0.2756 - val_loss: 12.3647 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.3196 - acc: 0.2756 - val_loss: 12.2689 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 2.4e-03\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 233\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_27 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 233)               15145     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 233)               54522     \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 233)               54522     \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 1)                 234       \n",
            "=================================================================\n",
            "Total params: 124,871\n",
            "Trainable params: 124,871\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 60us/step - loss: 11.6793 - acc: 0.2756 - val_loss: 11.5560 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 36us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 35us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 3.1e-05\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 429\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_29 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 429)               27885     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 429)               184470    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 429)               184470    \n",
            "_________________________________________________________________\n",
            "dense_30 (Dense)             (None, 1)                 430       \n",
            "=================================================================\n",
            "Total params: 397,703\n",
            "Trainable params: 397,703\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 64us/step - loss: 12.5689 - acc: 0.2756 - val_loss: 12.5315 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 39us/step - loss: 12.5027 - acc: 0.2756 - val_loss: 12.4668 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.4386 - acc: 0.2756 - val_loss: 12.4040 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 2.3e-05\n",
            "num_dense_layers: 4\n",
            "num_dense_nodes: 47\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_31 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 47)                3055      \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 47)                2256      \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 47)                2256      \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 47)                2256      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 1)                 48        \n",
            "=================================================================\n",
            "Total params: 10,319\n",
            "Trainable params: 10,319\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 68us/step - loss: 12.5967 - acc: 0.2756 - val_loss: 12.5672 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.5451 - acc: 0.2756 - val_loss: 12.5159 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.4940 - acc: 0.2756 - val_loss: 12.4655 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.0e-06\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 62\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 62)                4030      \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 62)                3906      \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 62)                3906      \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 1)                 63        \n",
            "=================================================================\n",
            "Total params: 12,353\n",
            "Trainable params: 12,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 63us/step - loss: 12.6061 - acc: 0.2756 - val_loss: 12.6051 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 35us/step - loss: 12.6039 - acc: 0.2756 - val_loss: 12.6028 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 36us/step - loss: 12.6014 - acc: 0.2756 - val_loss: 12.6005 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 3.7e-03\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 385\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_35 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 385)               25025     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 385)               148610    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 385)               148610    \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 1)                 386       \n",
            "=================================================================\n",
            "Total params: 323,079\n",
            "Trainable params: 323,079\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 70us/step - loss: 11.6435 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 38us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 7.4e-06\n",
            "num_dense_layers: 3\n",
            "num_dense_nodes: 67\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_37 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 67)                4355      \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 67)                4556      \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 67)                4556      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 1)                 68        \n",
            "=================================================================\n",
            "Total params: 13,983\n",
            "Trainable params: 13,983\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 70us/step - loss: 12.6070 - acc: 0.2756 - val_loss: 12.5978 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 36us/step - loss: 12.5902 - acc: 0.2756 - val_loss: 12.5810 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 36us/step - loss: 12.5733 - acc: 0.2756 - val_loss: 12.5643 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.0e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 490\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_39 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 490)               31850     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 1)                 491       \n",
            "=================================================================\n",
            "Total params: 32,789\n",
            "Trainable params: 32,789\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 64us/step - loss: 12.5607 - acc: 0.2756 - val_loss: 12.5514 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 32us/step - loss: 12.5585 - acc: 0.2756 - val_loss: 12.5492 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 31us/step - loss: 12.5563 - acc: 0.2756 - val_loss: 12.5469 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 9.2e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 20\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_41 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 20)                1300      \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 20)                420       \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 3,449\n",
            "Trainable params: 3,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 82us/step - loss: 11.5877 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 42us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 43us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.3e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 504\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_43 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 504)               32760     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 504)               254520    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 504)               254520    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 504)               254520    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 504)               254520    \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 1)                 505       \n",
            "=================================================================\n",
            "Total params: 1,051,793\n",
            "Trainable params: 1,051,793\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 88us/step - loss: 12.5868 - acc: 0.2756 - val_loss: 12.5803 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 41us/step - loss: 12.5839 - acc: 0.2756 - val_loss: 12.5774 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 41us/step - loss: 12.5811 - acc: 0.2756 - val_loss: 12.5744 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 7.8e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 509\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_45 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 509)               33085     \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 1)                 510       \n",
            "=================================================================\n",
            "Total params: 34,043\n",
            "Trainable params: 34,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 74us/step - loss: 11.5934 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 33us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 5.7e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 483\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_47 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 483)               31395     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 483)               233772    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 483)               233772    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 483)               233772    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 483)               233772    \n",
            "_________________________________________________________________\n",
            "dense_48 (Dense)             (None, 1)                 484       \n",
            "=================================================================\n",
            "Total params: 967,415\n",
            "Trainable params: 967,415\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 94us/step - loss: 11.6098 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 42us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 42us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 9.9e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 10\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_49 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,109\n",
            "Trainable params: 1,109\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 2s 80us/step - loss: 11.5805 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 9\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_51 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 9)                 585       \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 9)                 90        \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 1)                 10        \n",
            "=================================================================\n",
            "Total params: 1,403\n",
            "Trainable params: 1,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 96us/step - loss: 12.5600 - acc: 0.2756 - val_loss: 12.5564 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 42us/step - loss: 12.5573 - acc: 0.2756 - val_loss: 12.5539 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 44us/step - loss: 12.5551 - acc: 0.2756 - val_loss: 12.5515 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 491\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_53 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 491)               31915     \n",
            "_________________________________________________________________\n",
            "dense_54 (Dense)             (None, 1)                 492       \n",
            "=================================================================\n",
            "Total params: 32,855\n",
            "Trainable params: 32,855\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 86us/step - loss: 12.6041 - acc: 0.2756 - val_loss: 12.5983 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 12.6014 - acc: 0.2756 - val_loss: 12.5957 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 12.5987 - acc: 0.2756 - val_loss: 12.5931 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 9.0e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 510\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_55 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 510)               33150     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 510)               260610    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 510)               260610    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 510)               260610    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 510)               260610    \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 1)                 511       \n",
            "=================================================================\n",
            "Total params: 1,076,549\n",
            "Trainable params: 1,076,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 107us/step - loss: 11.5863 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 45us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 44us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 7.1e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 31\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_57 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 31)                2015      \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 2,495\n",
            "Trainable params: 2,495\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 93us/step - loss: 11.5941 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.5e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 496\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_59 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 496)               32240     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 496)               246512    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 496)               246512    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 496)               246512    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 496)               246512    \n",
            "_________________________________________________________________\n",
            "dense_60 (Dense)             (None, 1)                 497       \n",
            "=================================================================\n",
            "Total params: 1,019,233\n",
            "Trainable params: 1,019,233\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 113us/step - loss: 12.5736 - acc: 0.2756 - val_loss: 12.5694 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 44us/step - loss: 12.5702 - acc: 0.2756 - val_loss: 12.5661 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 45us/step - loss: 12.5668 - acc: 0.2756 - val_loss: 12.5628 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 499\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_61 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 499)               32435     \n",
            "_________________________________________________________________\n",
            "dense_62 (Dense)             (None, 1)                 500       \n",
            "=================================================================\n",
            "Total params: 33,383\n",
            "Trainable params: 33,383\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 98us/step - loss: 12.5617 - acc: 0.2756 - val_loss: 12.5615 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 34us/step - loss: 12.5595 - acc: 0.2756 - val_loss: 12.5589 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.5569 - acc: 0.2756 - val_loss: 12.5563 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 19\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_63 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 19)                1235      \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 19)                380       \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 19)                380       \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 19)                380       \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 19)                380       \n",
            "_________________________________________________________________\n",
            "dense_64 (Dense)             (None, 1)                 20        \n",
            "=================================================================\n",
            "Total params: 3,223\n",
            "Trainable params: 3,223\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 118us/step - loss: 12.6151 - acc: 0.2756 - val_loss: 12.6127 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 44us/step - loss: 12.6126 - acc: 0.2756 - val_loss: 12.6103 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 45us/step - loss: 12.6104 - acc: 0.2756 - val_loss: 12.6079 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 8.9e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 13\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_65 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 13)                845       \n",
            "_________________________________________________________________\n",
            "dense_66 (Dense)             (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 1,307\n",
            "Trainable params: 1,307\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 104us/step - loss: 11.5871 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 36us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 6.6e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 503\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_67 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 503)               32695     \n",
            "_________________________________________________________________\n",
            "dense_68 (Dense)             (None, 1)                 504       \n",
            "=================================================================\n",
            "Total params: 33,647\n",
            "Trainable params: 33,647\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 105us/step - loss: 11.6019 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 36us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 35us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.2e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 7\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_69 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 7)                 455       \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 1)                 8         \n",
            "=================================================================\n",
            "Total params: 911\n",
            "Trainable params: 911\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 3s 108us/step - loss: 12.5902 - acc: 0.2756 - val_loss: 12.5861 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 36us/step - loss: 12.5876 - acc: 0.2756 - val_loss: 12.5834 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.5848 - acc: 0.2756 - val_loss: 12.5807 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 6.2e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 505\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_71 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 505)               32825     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 505)               255530    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 505)               255530    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 505)               255530    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 505)               255530    \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 1)                 506       \n",
            "=================================================================\n",
            "Total params: 1,055,899\n",
            "Trainable params: 1,055,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 129us/step - loss: 11.6043 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 45us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 45us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 8.8e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 7\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_73 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 7)                 455       \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 7)                 56        \n",
            "_________________________________________________________________\n",
            "dense_74 (Dense)             (None, 1)                 8         \n",
            "=================================================================\n",
            "Total params: 1,135\n",
            "Trainable params: 1,135\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 131us/step - loss: 11.5875 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 45us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 45us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.4e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 503\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_75 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 503)               32695     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 503)               253512    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 503)               253512    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 503)               253512    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 503)               253512    \n",
            "_________________________________________________________________\n",
            "dense_76 (Dense)             (None, 1)                 504       \n",
            "=================================================================\n",
            "Total params: 1,047,695\n",
            "Trainable params: 1,047,695\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 140us/step - loss: 12.5636 - acc: 0.2756 - val_loss: 12.5564 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 47us/step - loss: 12.5605 - acc: 0.2756 - val_loss: 12.5534 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 46us/step - loss: 12.5575 - acc: 0.2756 - val_loss: 12.5504 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 9.2e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 15\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_77 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 15)                975       \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 15)                240       \n",
            "_________________________________________________________________\n",
            "dense_78 (Dense)             (None, 1)                 16        \n",
            "=================================================================\n",
            "Total params: 2,399\n",
            "Trainable params: 2,399\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 145us/step - loss: 11.5841 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 46us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 47us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 9.7e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 496\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_79 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 496)               32240     \n",
            "_________________________________________________________________\n",
            "dense_80 (Dense)             (None, 1)                 497       \n",
            "=================================================================\n",
            "Total params: 33,185\n",
            "Trainable params: 33,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 132us/step - loss: 11.5891 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 38us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.3e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 509\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_81 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 509)               33085     \n",
            "_________________________________________________________________\n",
            "dense_82 (Dense)             (None, 1)                 510       \n",
            "=================================================================\n",
            "Total params: 34,043\n",
            "Trainable params: 34,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 133us/step - loss: 12.5943 - acc: 0.2756 - val_loss: 12.5856 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 38us/step - loss: 12.5912 - acc: 0.2756 - val_loss: 12.5826 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 37us/step - loss: 12.5882 - acc: 0.2756 - val_loss: 12.5796 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.3e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 12\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_83 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 12)                780       \n",
            "_________________________________________________________________\n",
            "dense_84 (Dense)             (None, 1)                 13        \n",
            "=================================================================\n",
            "Total params: 1,241\n",
            "Trainable params: 1,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 4s 136us/step - loss: 12.6487 - acc: 0.2756 - val_loss: 12.6431 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 41us/step - loss: 12.6458 - acc: 0.2756 - val_loss: 12.6402 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 40us/step - loss: 12.6428 - acc: 0.2756 - val_loss: 12.6372 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 10\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_85 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 10)                650       \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 10)                110       \n",
            "_________________________________________________________________\n",
            "dense_86 (Dense)             (None, 1)                 11        \n",
            "=================================================================\n",
            "Total params: 1,549\n",
            "Trainable params: 1,549\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 5s 154us/step - loss: 12.6611 - acc: 0.2756 - val_loss: 12.6574 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 2s 49us/step - loss: 12.6594 - acc: 0.2756 - val_loss: 12.6550 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 48us/step - loss: 12.6569 - acc: 0.2756 - val_loss: 12.6525 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.4e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 512\n",
            "activation: relu\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_87 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_88 (Dense)             (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,084,865\n",
            "Trainable params: 1,084,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 5s 157us/step - loss: 12.6573 - acc: 0.2756 - val_loss: 12.6538 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 48us/step - loss: 12.6541 - acc: 0.2756 - val_loss: 12.6506 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 2s 49us/step - loss: 12.6511 - acc: 0.2756 - val_loss: 12.6475 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 9.3e-03\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 16\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_89 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 16)                1040      \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 16)                272       \n",
            "_________________________________________________________________\n",
            "dense_90 (Dense)             (None, 1)                 17        \n",
            "=================================================================\n",
            "Total params: 2,593\n",
            "Trainable params: 2,593\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 5s 159us/step - loss: 11.5856 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 48us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 2s 49us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 9\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_91 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 9)                 585       \n",
            "_________________________________________________________________\n",
            "dense_92 (Dense)             (None, 1)                 10        \n",
            "=================================================================\n",
            "Total params: 1,043\n",
            "Trainable params: 1,043\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 5s 150us/step - loss: 12.6129 - acc: 0.2756 - val_loss: 12.6105 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 39us/step - loss: 12.6105 - acc: 0.2756 - val_loss: 12.6081 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 38us/step - loss: 12.6080 - acc: 0.2756 - val_loss: 12.6058 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 1.1e-06\n",
            "num_dense_layers: 5\n",
            "num_dense_nodes: 509\n",
            "activation: sigmoid\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_93 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 509)               33085     \n",
            "_________________________________________________________________\n",
            "layer_dense_2 (Dense)        (None, 509)               259590    \n",
            "_________________________________________________________________\n",
            "layer_dense_3 (Dense)        (None, 509)               259590    \n",
            "_________________________________________________________________\n",
            "layer_dense_4 (Dense)        (None, 509)               259590    \n",
            "_________________________________________________________________\n",
            "layer_dense_5 (Dense)        (None, 509)               259590    \n",
            "_________________________________________________________________\n",
            "dense_94 (Dense)             (None, 1)                 510       \n",
            "=================================================================\n",
            "Total params: 1,072,403\n",
            "Trainable params: 1,072,403\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 5s 175us/step - loss: 12.6357 - acc: 0.2756 - val_loss: 12.6310 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 2s 51us/step - loss: 12.6328 - acc: 0.2756 - val_loss: 12.6284 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 2s 50us/step - loss: 12.6303 - acc: 0.2756 - val_loss: 12.6257 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n",
            "learning rate: 8.9e-03\n",
            "num_dense_layers: 1\n",
            "num_dense_nodes: 506\n",
            "activation: tanh\n",
            "\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_95 (Dense)             (None, 64)                448       \n",
            "_________________________________________________________________\n",
            "layer_dense_1 (Dense)        (None, 506)               32890     \n",
            "_________________________________________________________________\n",
            "dense_96 (Dense)             (None, 1)                 507       \n",
            "=================================================================\n",
            "Total params: 33,845\n",
            "Trainable params: 33,845\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 30874 samples, validate on 13233 samples\n",
            "Epoch 1/3\n",
            "30874/30874 [==============================] - 5s 158us/step - loss: 11.5871 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 2/3\n",
            "30874/30874 [==============================] - 1s 41us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Epoch 3/3\n",
            "30874/30874 [==============================] - 1s 40us/step - loss: 11.5491 - acc: 0.2756 - val_loss: 11.5559 - val_acc: 0.2751\n",
            "Accuracy: 27.51%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPSOPlq8txJ2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3ee5cd74-5c8f-4f99-f067-09be1fed3422"
      },
      "source": [
        "\"Model parameters: \",search_result.x"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          fun: -0.27514546966819386\n",
              "    func_vals: array([-0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547,\n",
              "       -0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547,\n",
              "       -0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547,\n",
              "       -0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547,\n",
              "       -0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547,\n",
              "       -0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547,\n",
              "       -0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547,\n",
              "       -0.27514547, -0.27514547, -0.27514547, -0.27514547, -0.27514547])\n",
              "       models: [GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5) + WhiteKernel(noise_level=1),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420)]\n",
              " random_state: <mtrand.RandomState object at 0x7f208c7c5630>\n",
              "        space: Space([Real(low=1e-06, high=0.01, prior='log-uniform', transform='normalize'),\n",
              "       Integer(low=1, high=5),\n",
              "       Integer(low=5, high=512),\n",
              "       Categorical(categories=('relu', 'sigmoid', 'tanh'), prior=None)])\n",
              "        specs: {'args': {'n_jobs': 1, 'kappa': 1.96, 'xi': 0.01, 'n_restarts_optimizer': 5, 'n_points': 10000, 'callback': None, 'verbose': False, 'random_state': <mtrand.RandomState object at 0x7f208c7c5630>, 'y0': None, 'x0': [1e-05, 1, 16, 'relu'], 'acq_optimizer': 'auto', 'acq_func': 'EI', 'n_random_starts': 10, 'n_calls': 40, 'base_estimator': GaussianProcessRegressor(alpha=1e-10, copy_X_train=True,\n",
              "                         kernel=1**2 * Matern(length_scale=[1, 1, 1, 1, 1, 1], nu=2.5),\n",
              "                         n_restarts_optimizer=2, noise='gaussian',\n",
              "                         normalize_y=True, optimizer='fmin_l_bfgs_b',\n",
              "                         random_state=1728990420), 'dimensions': Space([Real(low=1e-06, high=0.01, prior='log-uniform', transform='normalize'),\n",
              "       Integer(low=1, high=5),\n",
              "       Integer(low=5, high=512),\n",
              "       Categorical(categories=('relu', 'sigmoid', 'tanh'), prior=None)]), 'func': <function optimization at 0x7f20434f6378>}, 'function': 'base_minimize'}\n",
              "            x: [1e-05, 1, 16, 'relu']\n",
              "      x_iters: [[1e-05, 1, 16, 'relu'], [0.006587190265852266, 4, 346, 'tanh'], [0.0015688065113537673, 2, 397, 'sigmoid'], [1.8827050959974614e-05, 2, 209, 'relu'], [4.752072356663935e-05, 4, 30, 'sigmoid'], [0.0024295784597029688, 3, 233, 'relu'], [3.0752988179216426e-05, 3, 429, 'relu'], [2.3278391190574582e-05, 4, 47, 'sigmoid'], [1.0245168617752513e-06, 3, 62, 'tanh'], [0.00365868597558686, 3, 385, 'sigmoid'], [7.378041771244988e-06, 3, 67, 'relu'], [1.0063705384605933e-06, 1, 490, 'tanh'], [0.009193837404756608, 5, 20, 'tanh'], [1.2943827155455755e-06, 5, 504, 'sigmoid'], [0.007777993180774041, 1, 509, 'tanh'], [0.005693824623481692, 5, 483, 'relu'], [0.009935426749527632, 1, 10, 'sigmoid'], [1.0814847838812608e-06, 5, 9, 'tanh'], [1.1306592747800162e-06, 1, 491, 'sigmoid'], [0.009034753063426625, 5, 510, 'relu'], [0.007091478326312792, 1, 31, 'tanh'], [1.4628965360857995e-06, 5, 496, 'tanh'], [1.1462108714202203e-06, 1, 499, 'relu'], [1.05539714573053e-06, 5, 19, 'sigmoid'], [0.008939212643920355, 1, 13, 'relu'], [0.006636807887440107, 1, 503, 'sigmoid'], [1.1797948512174996e-06, 1, 7, 'tanh'], [0.006211167630789674, 5, 505, 'tanh'], [0.008784194552763845, 5, 7, 'relu'], [1.3673778245891125e-06, 5, 503, 'relu'], [0.009177770157901421, 5, 15, 'sigmoid'], [0.009715860828067281, 1, 496, 'tanh'], [1.3139243885337633e-06, 1, 509, 'sigmoid'], [1.300778167266096e-06, 1, 12, 'relu'], [1.0875631812335197e-06, 5, 10, 'tanh'], [1.365094547622859e-06, 5, 512, 'relu'], [0.009271988435473626, 5, 16, 'sigmoid'], [1.0547501935734757e-06, 1, 9, 'sigmoid'], [1.1445266973486353e-06, 5, 509, 'sigmoid'], [0.008883571665874532, 1, 506, 'tanh']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}